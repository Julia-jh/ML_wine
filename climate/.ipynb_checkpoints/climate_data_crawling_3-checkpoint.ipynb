{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a29893c",
   "metadata": {},
   "source": [
    "# NCEI\n",
    "- 월평균 활용\n",
    "- https://apihub.kma.go.kr/\n",
    "    - 세계기상 > NCEI 관측.통계 > 3. 전세계 지상관측(월통계) : 1763년~2022년\n",
    "    - ※ NCEI(National Centers for Environmental Information, 국립환경정보센터)는 미국 NOAA의 소속된 기관으로 전세계 기상기후데이터를 수집·제공합니다.\n",
    "    - ※ 모든 자료가 2022년 12월 까지 존재합니다.\n",
    "## 참고 자료\n",
    "- document 파일\n",
    "    - 자료 소개서\n",
    "        - GSOM_readme.txt\n",
    "    - 자료 설명서\n",
    "        - GSOM_documentation.pdf\n",
    "    - 연/월 통합 상세 설명서\n",
    "        - GSOM_GSOY_Description_Document_v1.0.2_20200219.pdf\n",
    "- 지점정보\n",
    "    - 링크 내용은 동일함\n",
    "    - https://www.ncei.noaa.gov/pub/data/noaa/isd-history.txt(내용확인)\n",
    "    - https://www.ncei.noaa.gov/pub/data/noaa/isd-history.csv(파일다운로드)\n",
    "- 국가 코드\n",
    "    - Country list\n",
    "        - 국가명과 국가 2글자 표현 짝 정리된 것\n",
    "        - 후에 요청인자 중 stn 구성요소인 지점코드값의 국가 부분을 해석하는데에 사용\n",
    "- 파일 리스트\n",
    "    - File list\n",
    "        - 파일목록\n",
    "        - 파일명과 파일 크기가 나열됨\n",
    "        - 후술될 요청인자 중 stn의 구성요소인 지점코드 값으로 활용할 수 있음\n",
    "            - 국가 2글자, 망구분 1글자, 지점번호 9글자를 가져올 소스\n",
    "## 참고 사이트\n",
    "- 바이너리 변환: https://m.blog.naver.com/errorsoft666/222132918275\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf8e09",
   "metadata": {},
   "source": [
    "## 활용 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dd4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import urllib\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b90514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개인 고유 인증키\n",
    "# 각자 버전 활용해야 함\n",
    "AUTH = \"secrets Leak alerts로 인해 마스킹처리, 코드 run 원할시 기상청 API 허브 가입 후 활용해 주세요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f13dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장하는 함수\n",
    "def download_file(file_url, save_path):\n",
    "    with open(save_path, 'wb') as f: # 저장할 파일을 바이너리 쓰기 모드로 열기\n",
    "        response = requests.get(file_url) # 파일 URL에 GET 요청 보내기\n",
    "        f.write(response.content) # 응답의 내용을 파일에 쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5f8ac",
   "metadata": {},
   "source": [
    "## Country list\n",
    "- country-list.txt 파일을 불러와 DF로 정리\n",
    "- csv로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ecc1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS ID</th>\n",
       "      <th>COUNTRY NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ARUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ANTIGUA AND BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ASCENSION ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ST. MARTEEN, ST. EUSTATIUS, AND SABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ZAMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ZIMBABWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAMOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ST. MARTIN AND ST. BARTHOLOMEW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS ID                            COUNTRY NAME\n",
       "AA      NaN                                   ARUBA\n",
       "AC      NaN                     ANTIGUA AND BARBUDA\n",
       "AF      NaN                             AFGHANISTAN\n",
       "AG      NaN                                 ALGERIA\n",
       "AI      NaN                        ASCENSION ISLAND\n",
       "..      ...                                     ...\n",
       "YY      NaN    ST. MARTEEN, ST. EUSTATIUS, AND SABA\n",
       "ZA      NaN                                  ZAMBIA\n",
       "ZI      NaN                                ZIMBABWE\n",
       "ZM      NaN                                   SAMOA\n",
       "ZZ      NaN          ST. MARTIN AND ST. BARTHOLOMEW\n",
       "\n",
       "[293 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCountry = pd.read_table(\"rawdata_climate/country-list.txt\", sep = '    ', encoding = 'euc-kr', engine = 'python')\n",
    "dfCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0c2730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfCountry.reset_index(inplace = True)\n",
    "dfCountry['FIPS ID'] = dfCountry['index']\n",
    "dfCountry.drop('index', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd57bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS ID</th>\n",
       "      <th>COUNTRY NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>ARUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC</td>\n",
       "      <td>ANTIGUA AND BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI</td>\n",
       "      <td>ASCENSION ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>YY</td>\n",
       "      <td>ST. MARTEEN, ST. EUSTATIUS, AND SABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ZA</td>\n",
       "      <td>ZAMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>ZI</td>\n",
       "      <td>ZIMBABWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ZM</td>\n",
       "      <td>SAMOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>ZZ</td>\n",
       "      <td>ST. MARTIN AND ST. BARTHOLOMEW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIPS ID                            COUNTRY NAME\n",
       "0        AA                                   ARUBA\n",
       "1        AC                     ANTIGUA AND BARBUDA\n",
       "2        AF                             AFGHANISTAN\n",
       "3        AG                                 ALGERIA\n",
       "4        AI                        ASCENSION ISLAND\n",
       "..      ...                                     ...\n",
       "288      YY    ST. MARTEEN, ST. EUSTATIUS, AND SABA\n",
       "289      ZA                                  ZAMBIA\n",
       "290      ZI                                ZIMBABWE\n",
       "291      ZM                                   SAMOA\n",
       "292      ZZ          ST. MARTIN AND ST. BARTHOLOMEW\n",
       "\n",
       "[293 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ee47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCountry.to_csv('data_climate/country_list.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d14d5d",
   "metadata": {},
   "source": [
    "## 전세계 지상관측(월통계) : 1763년~2022년\n",
    "- filelist 내용\n",
    "--------------------------------------------------------------------------------------------------\n",
    "미국 NCEI 전세계 지상관측 월통계의 연도별 파일목록  \n",
    "예) http://api.kma.go.kr/url/ncei_gsom_list.php\n",
    "--------------------------------------------------------------------------------------------------\n",
    "1. FILE : file name (지점코드.csv)\n",
    "2. SIZE : file size (bytes)\n",
    "--------------------------------------------------------------------------------------------------\n",
    "FILE,SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c844c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL과 저장 경로 변수를 지정합니다.\n",
    "url = \"https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_list.php?authKey=\" + AUTH\n",
    "save_file_path = 'rawdata_climate/filelist.txt'\n",
    "\n",
    "# 파일 다운로드 함수를 호출합니다.\n",
    "download_file(url, save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef2d27c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#          FILE</th>\n",
       "      <th>SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gsom_ACW00011604.csv</td>\n",
       "      <td>4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gsom_ACW00011647.csv</td>\n",
       "      <td>34313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gsom_AE000041196.csv</td>\n",
       "      <td>130742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gsom_AEM00041194.csv</td>\n",
       "      <td>100242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gsom_AEM00041217.csv</td>\n",
       "      <td>85259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122231</th>\n",
       "      <td>gsom_ZI000067965.csv</td>\n",
       "      <td>114617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122232</th>\n",
       "      <td>gsom_ZI000067969.csv</td>\n",
       "      <td>116596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122233</th>\n",
       "      <td>gsom_ZI000067975.csv</td>\n",
       "      <td>200883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122234</th>\n",
       "      <td>gsom_ZI000067977.csv</td>\n",
       "      <td>84153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122235</th>\n",
       "      <td>gsom_ZI000067983.csv</td>\n",
       "      <td>193672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             #          FILE    SIZE\n",
       "0       gsom_ACW00011604.csv    4036\n",
       "1       gsom_ACW00011647.csv   34313\n",
       "2       gsom_AE000041196.csv  130742\n",
       "3       gsom_AEM00041194.csv  100242\n",
       "4       gsom_AEM00041217.csv   85259\n",
       "...                      ...     ...\n",
       "122231  gsom_ZI000067965.csv  114617\n",
       "122232  gsom_ZI000067969.csv  116596\n",
       "122233  gsom_ZI000067975.csv  200883\n",
       "122234  gsom_ZI000067977.csv   84153\n",
       "122235  gsom_ZI000067983.csv  193672\n",
       "\n",
       "[122236 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFileList = pd.read_table(\"rawdata_climate/filelist.txt\", sep = ',', header = 7,\n",
    "                           encoding = 'euc-kr', engine = 'python', )\n",
    "dfFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2910d1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILE</th>\n",
       "      <th>SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gsom_ACW00011604.csv</td>\n",
       "      <td>4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gsom_ACW00011647.csv</td>\n",
       "      <td>34313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gsom_AE000041196.csv</td>\n",
       "      <td>130742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gsom_AEM00041194.csv</td>\n",
       "      <td>100242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gsom_AEM00041217.csv</td>\n",
       "      <td>85259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122231</th>\n",
       "      <td>gsom_ZI000067965.csv</td>\n",
       "      <td>114617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122232</th>\n",
       "      <td>gsom_ZI000067969.csv</td>\n",
       "      <td>116596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122233</th>\n",
       "      <td>gsom_ZI000067975.csv</td>\n",
       "      <td>200883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122234</th>\n",
       "      <td>gsom_ZI000067977.csv</td>\n",
       "      <td>84153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122235</th>\n",
       "      <td>gsom_ZI000067983.csv</td>\n",
       "      <td>193672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        FILE    SIZE\n",
       "0       gsom_ACW00011604.csv    4036\n",
       "1       gsom_ACW00011647.csv   34313\n",
       "2       gsom_AE000041196.csv  130742\n",
       "3       gsom_AEM00041194.csv  100242\n",
       "4       gsom_AEM00041217.csv   85259\n",
       "...                      ...     ...\n",
       "122231  gsom_ZI000067965.csv  114617\n",
       "122232  gsom_ZI000067969.csv  116596\n",
       "122233  gsom_ZI000067975.csv  200883\n",
       "122234  gsom_ZI000067977.csv   84153\n",
       "122235  gsom_ZI000067983.csv  193672\n",
       "\n",
       "[122236 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFileList.columns = [\"FILE\", \"SIZE\"]\n",
    "dfFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55853de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFileList.to_csv('data_climate/file_list.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075af30",
   "metadata": {},
   "source": [
    "# 여기서부터 파일 누적하여 만들어야 함\n",
    "- 윗부분은 이미 다 만들어서 여러 번 할 필요 X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c577568",
   "metadata": {},
   "source": [
    "## 전세계 지상관측(월통계) 호출 방법\n",
    "- 호출URL정보 예시\n",
    "    - 여러 지점\n",
    "        - https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_data.php?tm=202208&stns=KSM00047108,KSM00047159&authKey=AUTH\n",
    "    - 시간 구간\n",
    "        - https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_data.php?tm1=202201&tm2=202208&stns=KSM00047108,KSM00047159&authKey=AUTH\n",
    "    - 임의 영역내\n",
    "        - https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_data.php?tm=202208&lon1=125&lon2=130&lat1=32&lat2=38&authKey=AUTH\n",
    "    - 1개 지점의 전체 자료\n",
    "        - https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_file.php?stn=KSM00047108&authKey=AUTH\n",
    "### 요청 인자\n",
    "- tm\n",
    "    - 년월일시분(UTC)\n",
    "    - 특정시간대만 추출할 때\n",
    "- tm1\n",
    "    - 년월일시분(UTC)\n",
    "    - tm1~tm2 기간의 자료를 추출\n",
    "- tm2\n",
    "    - 년월일시분(UTC)\n",
    "    - tm1~tm2 기간의 자료를 추출\n",
    "- stns\n",
    "    - 지점들\n",
    "    - 여러지점코드를 ,로 구분하면 같이 처리함\n",
    "    - *) 지점코드 : 국가(2글자)+망구분(1글자)+지점번호(9글자)\n",
    "- lon1\n",
    "    - 영역\n",
    "    - 경도 [lon1~lon2] 내 자료들만 추출 (앞에 stns가 정의되어 있으면, stns을 우선함)\n",
    "- lon2\n",
    "    - 영역\n",
    "    - 경도 [lon1~lon2] 내 자료들만 추출 (앞에 stns가 정의되어 있으면, stns을 우선함)\n",
    "- lat1\n",
    "    - 영역\n",
    "    - 위도 [lat1~lat2] 내 자료들만 추출 (앞에 stns가 정의되어 있으면, stns을 우선함)\n",
    "- lat2\n",
    "    - 영역\n",
    "    - 위도 [lat1~lat2] 내 자료들만 추출 (앞에 stns가 정의되어 있으면, stns을 우선함)\n",
    "- authKey\n",
    "    - 인증키\n",
    "    - 발급된 API 인증키"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10276cab",
   "metadata": {},
   "source": [
    "- 모든 나라의 데이터 기간을 통일하기 위해 임의로 200001부터 202212까지로 정해서 불러와본다.\n",
    "- stn 코드값은 위의 filelist의 FILE 컬럼 내부 값을 조정하여 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e8e987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122236\n",
      "['ACW00011604', 'ACW00011647', 'AE000041196', 'AEM00041194', 'AEM00041217']\n"
     ]
    }
   ],
   "source": [
    "stnList = []\n",
    "for idx, row in dfFileList.iterrows():\n",
    "    tmp = row[0][5:-4]\n",
    "    stnList.append(tmp)\n",
    "print(len(stnList))\n",
    "print(stnList[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69f031",
   "metadata": {},
   "source": [
    "### 1개 지점의 전체 자료를 txt로 저장한 후 csv로 변환해 저장\n",
    "- 굳이 txt로 저장한 후 csv로 저장할 필요 있나 싶어 csv로 바로 저장했는데 문제가 없어서 일단 두 버전 둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b261b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt > csv\n",
    "for STN in stnList[:10]:\n",
    "\n",
    "    # URL과 저장 경로 변수를 지정합니다.\n",
    "    domain = \"https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_file.php?\"\n",
    "\n",
    "    stns = \"stn=\" + STN\n",
    "    authKey = \"&authKey=\" + AUTH\n",
    "\n",
    "    url = domain + stns + authKey\n",
    "\n",
    "    save_file_path = 'rawdata_climate/' + str(STN) + '.txt'\n",
    "\n",
    "    # 파일 다운로드 함수를 호출합니다.\n",
    "    download_file(url, save_file_path)\n",
    "    \n",
    "varList = []\n",
    "for STN in stnList[:10]:\n",
    "    varNM = 'df_{}'.format(STN)\n",
    "    \n",
    "    globals()[varNM] = pd.read_table('rawdata_climate/' + str(STN) + '.txt', sep = ',',\n",
    "                                      encoding = 'euc-kr', engine = 'python')\n",
    "    varList.append(varNM)\n",
    "    \n",
    "    globals()[varNM].to_csv('data_climate/' + str(STN) + '.csv', index = False)\n",
    "\n",
    "# 변수명 리스트\n",
    "print(varList)\n",
    "\n",
    "# 변수명 리스트에서 str 값을 변수로 활용하는 방법\n",
    "globals()[varList[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb5ff8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACW00011604\n",
      "ACW00011647\n",
      "AE000041196\n",
      "AEM00041194\n",
      "AEM00041217\n",
      "AEM00041218\n",
      "AF000040930\n",
      "AFM00040938\n",
      "AFM00040948\n",
      "AFM00040990\n",
      "AG000060390\n",
      "AG000060590\n",
      "AG000060611\n",
      "AG000060680\n",
      "AGE00135039\n",
      "AGE00147704\n",
      "AGE00147705\n",
      "AGE00147706\n",
      "AGE00147707\n",
      "AGE00147708\n",
      "AGE00147709\n",
      "AGE00147710\n",
      "AGE00147711\n",
      "AGE00147712\n",
      "AGE00147713\n",
      "AGE00147714\n",
      "AGE00147715\n",
      "AGE00147716\n",
      "AGE00147717\n",
      "AGE00147718\n",
      "AGE00147719\n",
      "AGE00147720\n",
      "AGE00147780\n",
      "AGE00147794\n",
      "AGM00060351\n",
      "AGM00060353\n",
      "AGM00060355\n",
      "AGM00060360\n",
      "AGM00060367\n",
      "AGM00060369\n",
      "AGM00060387\n",
      "AGM00060402\n",
      "AGM00060403\n",
      "AGM00060405\n",
      "AGM00060410\n",
      "AGM00060415\n",
      "AGM00060417\n",
      "AGM00060419\n",
      "AGM00060421\n",
      "AGM00060423\n",
      "AGM00060425\n",
      "AGM00060430\n",
      "AGM00060437\n",
      "AGM00060444\n",
      "AGM00060445\n",
      "AGM00060452\n",
      "AGM00060457\n",
      "AGM00060461\n",
      "AGM00060467\n",
      "AGM00060468\n",
      "AGM00060471\n",
      "AGM00060475\n",
      "AGM00060476\n",
      "AGM00060490\n",
      "AGM00060506\n",
      "AGM00060507\n",
      "AGM00060511\n",
      "AGM00060514\n",
      "AGM00060515\n",
      "AGM00060518\n",
      "AGM00060520\n",
      "AGM00060522\n",
      "AGM00060531\n",
      "AGM00060535\n",
      "AGM00060536\n",
      "AGM00060540\n",
      "AGM00060549\n",
      "AGM00060550\n",
      "AGM00060555\n",
      "AGM00060557\n",
      "AGM00060559\n",
      "AGM00060560\n",
      "AGM00060563\n",
      "AGM00060566\n",
      "AGM00060571\n",
      "AGM00060580\n",
      "AGM00060581\n",
      "AGM00060602\n",
      "AGM00060603\n",
      "AGM00060607\n",
      "AGM00060620\n",
      "AGM00060630\n",
      "AGM00060640\n",
      "AGM00060656\n",
      "AGM00060670\n",
      "AGM00060690\n",
      "AJ000037575\n",
      "AJ000037579\n",
      "AJ000037605\n",
      "AJ000037636\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'euc_kr' codec can't decode byte 0x80 in position 79: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m STN \u001b[38;5;129;01min\u001b[39;00m stnList[startNum:endNum]:\n\u001b[0;32m     26\u001b[0m     varNM \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(STN)\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[varNM] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_climate/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSTN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meuc-kr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     varList\u001b[38;5;241m.\u001b[39mappend(varNM)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 변수명 리스트\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:124\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]]\n\u001b[0;32m    120\u001b[0m (\n\u001b[0;32m    121\u001b[0m     columns,\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_original_columns,\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols,\n\u001b[1;32m--> 124\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[0;32m    129\u001b[0m (\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    137\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:397\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level, hr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(header):\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_pos \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m hr:\n\u001b[0;32m    400\u001b[0m             line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_line()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:630\u001b[0m, in \u001b[0;36mPythonParser._buffered_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:731\u001b[0m, in \u001b[0;36mPythonParser._next_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 731\u001b[0m     orig_line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orig_line \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ds_study\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:795\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;66;03m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(line, \u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'euc_kr' codec can't decode byte 0x80 in position 79: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# csv로 바로 저장\n",
    "\n",
    "startNum = 0\n",
    "endNum = 100\n",
    "\n",
    "for i, STN in enumerate(stnList[startNum:endNum]):\n",
    "\n",
    "    # URL과 저장 경로 변수를 지정합니다.\n",
    "    domain = \"https://apihub.kma.go.kr/api/typ01/url/ncei_gsom_file.php?\"\n",
    "\n",
    "    stns = \"stn=\" + STN\n",
    "    authKey = \"&authKey=\" + AUTH\n",
    "\n",
    "    url = domain + stns + authKey\n",
    "\n",
    "    save_file_path = 'data_climate/' + str(STN) + '.csv'\n",
    "\n",
    "    # 파일 다운로드 함수를 호출합니다.\n",
    "    download_file(url, save_file_path)\n",
    "    \n",
    "    # 확인용 호출\n",
    "    print(STN)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print('-----------------------------------')\n",
    "        print(i + '번째')\n",
    "    \n",
    "varList = []\n",
    "for STN in stnList[startNum:endNum]:\n",
    "    varNM = 'df_{}'.format(STN)\n",
    "    \n",
    "    globals()[varNM] = pd.read_csv('data_climate/' + str(STN) + '.csv', sep = ',',\n",
    "                                      encoding = 'euc-kr', engine = 'python')\n",
    "    varList.append(varNM)\n",
    "    \n",
    "# 변수명 리스트\n",
    "print(varList)\n",
    "\n",
    "# 변수명 리스트에서 str 값을 변수로 활용하는 방법\n",
    "# 랜덤으로 확인하기\n",
    "tmp = int((startNum + endNum) / 2)\n",
    "globals()[varList[tmp]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7478b2",
   "metadata": {},
   "source": [
    "# 오류 발생 가능성 때문에 txt로 시작할까 고민중!!!\n",
    "# 근데 csv 파일 전체 다운하는것을 발견했다!!!!!!!!\n",
    "# 그래도 유럽 국가만 고르기 위해 기준 파일은 필요할 듯!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "ds_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
